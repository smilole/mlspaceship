{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27641a9d0166a37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Подключаем необходимые библиотеки\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Функция для подготовки данных\n",
    "def data_preparation(data_frame):\n",
    "\n",
    "    # Создаем новые столбцы\n",
    "    data_frame['deck'] = data_frame['Cabin'].str.slice(0, 1)  # deck\n",
    "    data_frame['num'] = data_frame['Cabin'].str.extract(r'(\\d+)')  # num\n",
    "    data_frame['side'] = data_frame['Cabin'].str.slice(4, 5)  # side\n",
    "\n",
    "    # Приводим номер каюты к числу\n",
    "    data_frame['num'] = pd.to_numeric(data_frame['num'], errors='coerce')\n",
    "\n",
    "    # Удаляем изначальный стобец кают - он больше нам не нужен\n",
    "    data_frame.drop(columns='Cabin', inplace=True)\n",
    "\n",
    "    # Заполняем пропуски\n",
    "    mode_features = ['HomePlanet', 'Destination', 'side', 'num', 'deck'] # так как эти значение ограничены несколькими вариантами - заполняем их по моде\n",
    "\n",
    "    for f in mode_features:\n",
    "        # .iloc[0]- получение первой моды из результата вычисления моды\n",
    "        data_frame[f] = data_frame[f].fillna(data_frame[f].mode().iloc[0])\n",
    "\n",
    "    # Бинарные признаки\n",
    "    bin_feats = ['CryoSleep', 'VIP','side']\n",
    "\n",
    "    # Категориальные признаки\n",
    "    cat_feats = ['HomePlanet', 'Destination','deck']\n",
    "\n",
    "    # Преобразование бинарных признаков в числовой формат\n",
    "    for f in bin_feats:\n",
    "        map_dict = {value: i for i, value in enumerate(set(data_frame[f]))}\n",
    "        data_frame[f] = data_frame[f].map(map_dict)\n",
    "\n",
    "    # Преобразование категориальных признаков при помощи \"one-hot encoding\"\n",
    "    # Да, существует библиотека которая это делает автоматически, но частично код остался с прошлого модуля\n",
    "    for f in cat_feats:\n",
    "        values = set(data_frame[f])\n",
    "        for v in values:\n",
    "            data_frame[f + '_' + str(v)] = data_frame[f] == v\n",
    "        data_frame = data_frame.drop(columns=f)\n",
    "\n",
    "    # Заполняем пропуски в числовых столбцах средними значениями и округляем\n",
    "    numeric_columns = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        mean_value = data_frame[col].mean()\n",
    "        data_frame[col] = data_frame[col].fillna(mean_value).round()\n",
    "\n",
    "\n",
    "    #айдишники уникальны, однако из них можно получить полезную информацию, связанную с именами и каютами, но нужно думать как\n",
    "    data_frame = data_frame.drop(columns='PassengerId')\n",
    "    data_frame = data_frame.drop(columns='Name')\n",
    "\n",
    "    # все колонки кроме transported приводим к типу int64 чтобы модель могла без проблем работать с ними\n",
    "    for col in data_frame.columns:\n",
    "        if col != 'Transported':\n",
    "            data_frame[col] = data_frame[col].astype(\"int64\")\n",
    "\n",
    "    # Небольшой костыль: Если это обучающий датасет - он вернет X с данными пассажиров и y - с данными о transported\n",
    "    # Ну а если же это уже датасет для предсказания, то в нем нет колонки transported поэтому мы вернем только X - всю таблицу\n",
    "    if \"Transported\" not in data_frame.columns:\n",
    "        X = data_frame.values\n",
    "\n",
    "        return X\n",
    "\n",
    "    y = data_frame[\"Transported\"].values\n",
    "    X = data_frame.drop(\"Transported\", axis=1).values\n",
    "\n",
    "    return X,y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f467f609862a9a6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Функция для обучения модели и её сохранения\n",
    "def train(path_to_train_csv):\n",
    "\n",
    "    # Открываем файл по полученному пути\n",
    "    data_frame = pd.read_csv(path_to_train_csv)\n",
    "\n",
    "    # вызываем функцию для подготовки данных для обучения модели\n",
    "    X, y = data_preparation(data_frame)\n",
    "\n",
    "    # Разделяем данные на обучающий и валидационный наборы\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    def objective(trial):\n",
    "        # задаём значения для перебора параметров\n",
    "        iterations = trial.suggest_int('iterations', 100, 1000)\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.001, 1.0)\n",
    "        depth = trial.suggest_int('depth', 1, 10)\n",
    "\n",
    "        # создаем модель с параметрами\n",
    "        model = CatBoostClassifier(iterations = iterations, learning_rate = learning_rate, depth = depth)\n",
    "\n",
    "        # Обучаем модель\n",
    "        model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "        # Делаем предсказания\n",
    "        pred = model.predict(X_val)\n",
    "\n",
    "        # вычисляем точность предсказания\n",
    "        accuracy = accuracy_score(y_val, pred)\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    # Создаем объект для оптимизации\n",
    "    study = optuna.create_study(direction='maximize')  # Максимизируем метрику производительности\n",
    "\n",
    "    # оптимизируем запуская objective n_trials раз\n",
    "    study.optimize(objective, n_trials=100,show_progress_bar=True)\n",
    "\n",
    "    # получаем лучшие параметры при оптимизации полученные из одного из trials\n",
    "    best_params = study.best_trial.params\n",
    "\n",
    "    # Создаем модель с лучшими параметрами для обучения\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=best_params['iterations'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        depth=best_params['depth']\n",
    "    )\n",
    "\n",
    "    # Обучаем модель\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "    # Сохраняем модель\n",
    "    joblib.dump(model, \"trained_model.pkl\")\n",
    "\n",
    "    print(\"Model has trained\")\n",
    "\n",
    "    return"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "746e4a16c47d0fb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Функция для предсказания при помощи сохраненной модели\n",
    "def predict(path_to_predict_csv):\n",
    "\n",
    "    # Открываем файл по полученному пути\n",
    "    data_frame = pd.read_csv(path_to_predict_csv)\n",
    "\n",
    "    # Подготавливаем данные для предсказания\n",
    "    X = data_preparation(data_frame)\n",
    "\n",
    "    # Достаем ранее сохраненную модель\n",
    "    model = joblib.load(\"trained_model.pkl\")\n",
    "\n",
    "    # Делаем предсказание и сохраняем его\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    # Создаем новый датафрейм с айдишника пассажиров и предсказанием\n",
    "    new_data_frame = pd.DataFrame({'PassengerId': data_frame['PassengerId'],'Transported': prediction})\n",
    "\n",
    "    # Сохраняем предсказание в csv\n",
    "    new_data_frame.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    print(\"prediction saved\")\n",
    "\n",
    "    return\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3785456c3fbdf79b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # указываем параметры необходимые к передаче\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"mode\", choices=[\"train\", \"predict\"])\n",
    "    parser.add_argument(\"--dataset\", required=True)\n",
    "\n",
    "    # Считываем параметры\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Если train - обучаем модель, если predict - делаем предсказание\n",
    "    if args.mode == \"train\":\n",
    "        train(args.dataset)\n",
    "    elif args.mode == \"predict\":\n",
    "        predict(args.dataset)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "Код в model.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57b82ec4ddfaae89"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a7d7bbf5988bf68e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
